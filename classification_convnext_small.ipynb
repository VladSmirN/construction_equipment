{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport pandas as pd \nimport numpy as np\nimport glob\nfrom tqdm import tqdm\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport os\n!pip install torchinfo\nfrom torchinfo import summary\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nfrom sklearn.metrics import recall_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, models, transforms\nfrom torchvision.models import resnet18\nimport uuid\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n!pip install git+https://github.com/openai/CLIP.git\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as A    \n    \nimport clip\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:15:37.368755Z","iopub.execute_input":"2022-10-23T14:15:37.369219Z","iopub.status.idle":"2022-10-23T14:16:21.222889Z","shell.execute_reply.started":"2022-10-23T14:15:37.369185Z","shell.execute_reply":"2022-10-23T14:16:21.221073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Настрока блокнота","metadata":{}},{"cell_type":"code","source":"class CFG:\n    batch_size=64\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    num_epochs = 10\n    wandb_project = \"construction_equipment\"\n    wandb_entity = \"vladsmirn_\"\n    img_size = 224\n    n_fold = 5\n    k_fold = 3\n    \n    \n    id_notebook=str(uuid.uuid4())\n    \nprint(\"id_notebook: \" + CFG.id_notebook)\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:16:21.225872Z","iopub.execute_input":"2022-10-23T14:16:21.227579Z","iopub.status.idle":"2022-10-23T14:16:21.242072Z","shell.execute_reply.started":"2022-10-23T14:16:21.227518Z","shell.execute_reply":"2022-10-23T14:16:21.240149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transform(phase: str, img_size: int):\n    if phase == 'train':\n        return Compose([\n#             A.Resize(height=img_size, width=img_size),\n            A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.97, 1.0)),\n            A.Flip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.1),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=0.2),\n                A.RandomGamma(p=0.2),\n            ], p=0.5),\n            A.OneOf([\n                A.Blur(p=0.1),\n                A.GaussianBlur(p=0.1),\n                A.MotionBlur(p=0.1),\n            ], p=0.1),\n            A.OneOf([\n                A.GaussNoise(p=0.1),\n                A.ISONoise(p=0.1),\n            ], p=0.2),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=img_size, width=img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:16:21.244933Z","iopub.execute_input":"2022-10-23T14:16:21.246345Z","iopub.status.idle":"2022-10-23T14:16:21.264528Z","shell.execute_reply.started":"2022-10-23T14:16:21.246286Z","shell.execute_reply":"2022-10-23T14:16:21.262803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR_TRAIN = \"../input/construction-equipment/train/\"\nDIR_TEST = \"../input/construction-equipment-test/test/\"\n\nPATH_TRAIN = \"../input/construction-equipment/train.csv\"\nPATH_TEST = \"../input/construction-equipment-test/test.csv\"\n\ndef KFOLD(df, n_fold=5 , k_fold=1, seed=43, column_x='path', column_y='class'):\n    skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n    \n    for i_fold , (train_idx, valid_idx) in enumerate(skf.split(df[column_x], df[column_y])):\n        if(i_fold+1 == k_fold):\n            df_train = df.iloc[train_idx]\n            df_valid = df.iloc[valid_idx]\n            break\n\n    print(f\"train size: {len(df_train)}\")\n    print(f\"valid size: {len(df_valid)}\")\n    \n    return df_train, df_valid\n\nclass ImageDataset(Dataset):\n    def __init__(self, data_df, transform=None):\n\n        self.data_df = data_df\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        image_path, label = self.data_df.iloc[idx]['path'], self.data_df.iloc[idx]['class']\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=image)['image'] \n#         image = image.permute(0,1,2) \n#         image = Image.fromarray(image)\n#         image = preprocess(image).to(device)  \n        return image, torch.tensor(label).long()\n    \n    def __len__(self):\n        return len(self.data_df)\n    \n \n \n\ndata_df = pd.read_csv(PATH_TRAIN)\ndata_df[\"path\"] = data_df[\"ID_img\"].apply(lambda image_name : f'{DIR_TRAIN}{image_name}')\ntrain_df, valid_df = KFOLD(data_df, n_fold=CFG.n_fold, k_fold=CFG.k_fold)\ntrain_dataset = ImageDataset(train_df, get_transform(\"train\",CFG.img_size))\nvalid_dataset = ImageDataset(valid_df, get_transform(\"valid\",CFG.img_size))\n \n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=CFG.batch_size,\n                                           shuffle=True)\n\nvalid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n                                           batch_size=CFG.batch_size)\n                                            \n# CFG.steps_per_epoch = len(train_loader)\nCFG.steps_per_epoch = len(train_loader) \nimages, labels =  next(iter(train_loader))\n# model_clip.encode_image(images[:1])\nimages.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:16:21.268810Z","iopub.execute_input":"2022-10-23T14:16:21.269426Z","iopub.status.idle":"2022-10-23T14:16:22.585805Z","shell.execute_reply.started":"2022-10-23T14:16:21.269391Z","shell.execute_reply":"2022-10-23T14:16:22.584260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n'''\nhttps://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling/notebook\n \nCFG.lr_schedule = \"OneCycleLR\"\nCFG.num_epochs = 10\nCFG.steps_per_epoch = 62\nCFG.max_lr = 0.0002\nCFG.div_factor = 2\n\nCFG.lr_schedule = \"CyclicLR_exp_range\" \nCFG.base_lr = 0.0001 \nCFG.max_lr = 0.0002 \nCFG.step_size_up = 100\nCFG.gamma = 0.992\n\n'''\n# class optimizers_confing: \n \ndef choose_configure_optimizers(CFG,model = torch.nn.Linear(2, 1),show=False):\n    \n  \n    CFG.optimizer = \"Adam\"\n    if not hasattr(CFG, 'lr'):\n        CFG.lr = 0.001\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)    \n\n         \n    if not hasattr(CFG, 'lr_schedule'):\n        return optimizer\n    \n \n    if CFG.lr_schedule == \"OneCycleLR\" :\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                                        epochs=CFG.num_epochs, \n                                                        steps_per_epoch= CFG.steps_per_epoch,\n                                                        max_lr=CFG.max_lr)\n                                                        \n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        number_steps_scheduler = CFG.steps_per_epoch * CFG.num_epochs # for show\n        \n        \n        \n        \n    if CFG.lr_schedule == \"CyclicLR_exp_range\" :\n        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n                                                      base_lr=CFG.base_lr, \n                                                      max_lr=CFG.max_lr, \n                                                      step_size_up=CFG.step_size_up,\n                                                      mode=\"exp_range\",\n                                                      gamma=CFG.gamma,\n                                                      cycle_momentum=False)\n        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n        number_steps_scheduler = CFG.steps_per_epoch * CFG.num_epochs\n        \n        \n        \n    if CFG.lr_schedule == \"LambdaLR\" :\n        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, \n                                                      lr_lambda = lambda epoch: CFG.parametr_lambda ** epoch)\n        \n        scheduler = {'scheduler': scheduler, 'interval': 'epoch'}\n        number_steps_scheduler = CFG.num_epochs\n        \n        \n        \n      \n        \n    if show : \n        lrs = []\n        for i in range(number_steps_scheduler):\n            optimizer.step()\n            lrs.append(optimizer.param_groups[0][\"lr\"])\n            scheduler['scheduler'].step()\n            \n        plt.title(CFG.lr_schedule)  \n        plt.plot(lrs)  \n        plt.xlabel(\"step\") \n        plt.ylabel(\"lr\")\n        plt.show()\n        print(\"last lr:\"+str(lrs[-1]))\n        print(\"first lr:\"+str(lrs[0]))\n        print(optimizer)\n\n    return optimizer, scheduler\n\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:54:40.647608Z","iopub.execute_input":"2022-10-23T14:54:40.648210Z","iopub.status.idle":"2022-10-23T14:54:40.665042Z","shell.execute_reply.started":"2022-10-23T14:54:40.648167Z","shell.execute_reply":"2022-10-23T14:54:40.664014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.lr_schedule = \"OneCycleLR\"\nCFG.num_epochs = 20\nCFG.max_lr = 0.0002\n\n \n_ = choose_configure_optimizers(CFG,show=True)\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T14:54:43.527965Z","iopub.execute_input":"2022-10-23T14:54:43.528385Z","iopub.status.idle":"2022-10-23T14:54:43.839043Z","shell.execute_reply.started":"2022-10-23T14:54:43.528352Z","shell.execute_reply":"2022-10-23T14:54:43.837413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##   Объявление модели\n","metadata":{}},{"cell_type":"code","source":"model_clf = models.convnext.convnext_small(pretrained=True)\nmodel_clf.classifier[2] = nn.Linear(768, 8) \n\nmodel_clf.to(CFG.device)\n\n \nsummary(model_clf)","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:29:12.873339Z","iopub.execute_input":"2022-10-23T13:29:12.873673Z","iopub.status.idle":"2022-10-23T13:29:26.860502Z","shell.execute_reply.started":"2022-10-23T13:29:12.873639Z","shell.execute_reply":"2022-10-23T13:29:26.859398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_recall_score(imgs,labels,model):\n    model.eval()\n    imgs = imgs.to(CFG.device)\n    pred = model(imgs)\n\n    pred_numpy = pred.cpu().detach().numpy()\n    valid_predicts=[]\n    for class_obj in pred_numpy:\n          index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n          valid_predicts.append(index)\n\n    return recall_score(labels.cpu().detach().numpy(), valid_predicts, average = \"macro\")\n\n\nclass LightNPairModel(pl.LightningModule):\n    def __init__(self, model,  lr=0.0001):\n        super(LightNPairModel, self).__init__()\n        self.model = model\n        self.criterion = torch.nn.CrossEntropyLoss()\n        self.lr = lr\n\n    def forward(self, x, label=False, *args, **kwargs):\n        return self.model(x[0])\n\n    def configure_optimizers(self):\n        optimizer, scheduler = choose_configure_optimizers(CFG,self.model)\n        self.optimizer = optimizer\n        return [self.optimizer],[scheduler]\n\n    \n    def training_step(self, batch, batch_idx):\n        images = batch[0]\n        labels = batch[1]\n        embedding = self.model(images)\n        loss = self.criterion(embedding, labels)\n        self.log('train_loss', loss)\n        self.log('lr', self.optimizer.param_groups[0]['lr'])\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        images = batch[0]\n        labels = batch[1]\n        embedding = self.model(images)\n        loss = self.criterion(embedding, labels)\n        score = compute_recall_score(images,labels,self.model)\n        self.log('valid_loss', loss)    \n        self.log('valid_score', score)   \n        return loss\n    \n#     def validation_epoch_end(self, validation_step_outputs):\n        \n# #         image_array = image_map(self.path_images,self.model,show=False, save=False) \n# #         self.logger.experiment.log({\"image\": [wandb.Image(image_array)]})\n#         self.log('valid_score',  compute_recall_score(valid_loader,model_clf))    \n        \nlit_model = LightNPairModel(model_clf, lr = CFG.lr)","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:29:26.865294Z","iopub.execute_input":"2022-10-23T13:29:26.868191Z","iopub.status.idle":"2022-10-23T13:29:26.951630Z","shell.execute_reply.started":"2022-10-23T13:29:26.868126Z","shell.execute_reply":"2022-10-23T13:29:26.950469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_wandb(wandb_api_key, cfg):\n    wandb.require(experiment=\"service\")\n    wandb.login(key=wandb_api_key)\n    _cfg = cfg() \n    cfg_wandb = dict((name, getattr(_cfg, name)) for name in dir(_cfg) if not name.startswith('__'))\n    \n    if hasattr(cfg, 'wandb_resume_id') and cfg.wandb_resume_id :\n        run = wandb.init(project=cfg.wandb_project, \n                   entity=cfg.wandb_entity, \n                   id=cfg.wandb_resume_id, \n                   resume=\"allow\", \n                   config=cfg_wandb)\n    else: \n        run = wandb.init(project=cfg.wandb_project, \n                   entity=cfg.wandb_entity, \n                   settings=wandb.Settings(start_method=\"fork\"), \n                   config=cfg_wandb,\n                   resume=\"allow\",\n                   id=wandb.util.generate_id())\n        \n    model_logger = WandbLogger(project=cfg.wandb_project, log_model='all')\n    \n    return model_logger,run\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nmodel_logger, _ = run_wandb(user_secrets.get_secret(\"WANDB_API_KEY\"), CFG)","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:29:26.953155Z","iopub.execute_input":"2022-10-23T13:29:26.955317Z","iopub.status.idle":"2022-10-23T13:29:36.194549Z","shell.execute_reply.started":"2022-10-23T13:29:26.955278Z","shell.execute_reply":"2022-10-23T13:29:36.193562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(monitor='valid_score',\n#                                       save_top_k=1,\n                                      save_weights_only=True,\n                                      verbose=False,\n                                      mode='max')\n\nif torch.cuda.is_available() : \n    trainer = Trainer(\n        max_epochs=CFG.num_epochs,\n        gpus=[0],\n        callbacks=[checkpoint_callback], \n        logger=model_logger,\n        log_every_n_steps = 1 \n    )\nelse :\n    trainer = Trainer(\n        max_epochs=CFG.num_epochs,\n        callbacks=[checkpoint_callback], \n        logger=model_logger,\n        log_every_n_steps = 1 \n    )","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:29:36.201252Z","iopub.execute_input":"2022-10-23T13:29:36.203534Z","iopub.status.idle":"2022-10-23T13:29:36.935063Z","shell.execute_reply.started":"2022-10-23T13:29:36.203491Z","shell.execute_reply":"2022-10-23T13:29:36.933842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:29:36.940706Z","iopub.execute_input":"2022-10-23T13:29:36.943100Z","iopub.status.idle":"2022-10-23T13:32:40.398808Z","shell.execute_reply.started":"2022-10-23T13:29:36.943058Z","shell.execute_reply":"2022-10-23T13:32:40.397790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Предсказание ","metadata":{}},{"cell_type":"code","source":"# _, run = run_wandb(user_secrets.get_secret(\"WANDB_API_KEY\"), CFG)\n# model_clf_best = classification_construction(model_clip)\n# artifact = run.use_artifact('vladsmirn_/construction_equipment/model-3qeaibwz:v14', type='model')\n# artifact_dir = artifact.download()\n# checkpoint =   os.path.join(artifact_dir, \"model.ckpt\" )\n\n# from collections import OrderedDict\n# state_dict = torch.load(checkpoint,map_location ='cpu')['state_dict']\n# new_state_dict = OrderedDict()\n# for k, v in state_dict.items():\n#     name = k[6:]  \n#     new_state_dict[name] = v\n\n# model_clf_best.load_state_dict(new_state_dict)\n\n ","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:32:40.400937Z","iopub.execute_input":"2022-10-23T13:32:40.401540Z","iopub.status.idle":"2022-10-23T13:32:40.412343Z","shell.execute_reply.started":"2022-10-23T13:32:40.401481Z","shell.execute_reply":"2022-10-23T13:32:40.411265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(PATH_TEST)\ntest_df[\"path\"] = test_df[\"ID_img\"].apply(lambda image_name : f'{DIR_TEST}{image_name}')\ntest_df = test_df.drop([\"class\"], axis = 1)\n\nclass TestImageDataset(Dataset):\n    def __init__(self, data_df, transform=None):\n        self.data_df = data_df\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        image_path = self.data_df.iloc[idx]['path']\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=image)['image'] \n \n        \n        return image\n    \n    def __len__(self):\n        return len(self.data_df)\n    \ntest_dataset = TestImageDataset(test_df,get_transform(\"valid\",CFG.img_size))","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:32:40.414023Z","iopub.execute_input":"2022-10-23T13:32:40.414377Z","iopub.status.idle":"2022-10-23T13:32:40.449227Z","shell.execute_reply.started":"2022-10-23T13:32:40.414342Z","shell.execute_reply":"2022-10-23T13:32:40.448284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                           batch_size=32,\n                                            )","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:32:40.453876Z","iopub.execute_input":"2022-10-23T13:32:40.456422Z","iopub.status.idle":"2022-10-23T13:32:40.464405Z","shell.execute_reply.started":"2022-10-23T13:32:40.456379Z","shell.execute_reply":"2022-10-23T13:32:40.463350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_clf, \"./model_clf.pt\")\n\nmodel_clf.eval()\npredicts = []\nmodel_clf.to(CFG.device)\nfor imgs in tqdm(test_loader):\n    \n    imgs = imgs.to(CFG.device)\n    pred = model_clf(imgs)\n    for class_obj in pred:\n      index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n      predicts.append(index)","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:32:40.469310Z","iopub.execute_input":"2022-10-23T13:32:40.472287Z","iopub.status.idle":"2022-10-23T13:33:06.284474Z","shell.execute_reply.started":"2022-10-23T13:32:40.472244Z","shell.execute_reply":"2022-10-23T13:33:06.283418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"class\"] = predicts\ntest_df = test_df.drop([\"path\"], axis = 1)\ntest_df.head()\n\ntest_df.to_csv(\"submit.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-23T13:33:06.288638Z","iopub.execute_input":"2022-10-23T13:33:06.291417Z","iopub.status.idle":"2022-10-23T13:33:06.310504Z","shell.execute_reply.started":"2022-10-23T13:33:06.291376Z","shell.execute_reply":"2022-10-23T13:33:06.309169Z"},"trusted":true},"execution_count":null,"outputs":[]}]}